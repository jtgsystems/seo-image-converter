#!/bin/bash

# JTG AI Image Converter - SEO Image Processor
# This script recursively finds images in a directory, converts them to WebP,
# and renames them using SEO keywords generated by a local Ollama Llava model.

set -e

# --- CONFIGURATION ---
# Model to use for generating descriptions
OLLAMA_MODEL="llava"
# Ollama API endpoint
OLLAMA_ENDPOINT="http://localhost:11434/api/generate"
# Number of parallel jobs to run (80% of available cores)
MAX_JOBS=$(($(nproc) * 8 / 10))
# Log file name
LOG_FILE="conversion_log.txt"
# Default quality
QUALITY=85
# Lossless mode (default off)
LOSSLESS=0

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --quality)
            QUALITY="$2"
            shift 2
            ;;
        --lossless)
            LOSSLESS=1
            shift
            ;;
        *)
            TARGET_DIR="$1"
            shift
            ;;
    esac
done

# 1. Validate Input
if [ -z "$TARGET_DIR" ]; then
    echo "Usage: $0 <image_directory> [--quality <1-100>] [--lossless]"
    echo "Example: $0 /path/to/your/images --quality 90 --lossless"
    exit 1
fi
if [ ! -d "$TARGET_DIR" ]; then
    echo "Error: Directory '$TARGET_DIR' not found."
    exit 1
fi

# Absolute path for the log file
LOG_FILE_PATH="$(pwd)/${LOG_FILE}"

# 2. Check Dependencies
for cmd in cwebp ollama jq exiftool; do
    if ! command -v "$cmd" &> /dev/null; then
        echo "Error: Required command '$cmd' is not installed. Please install it and try again."
        exit 1
    fi
done

# Check if Ollama is running
if ! ollama ps &> /dev/null; then
    echo "Error: Ollama is not running. Please start the Ollama service."
    exit 1
fi

echo "JTG AI Image Converter started."
echo "Target Directory: $TARGET_DIR"
echo "Using $MAX_JOBS parallel processes."
echo "Log file will be created at: $LOG_FILE_PATH"
echo "---"

# 3. Initialize Log File
echo "Image Conversion Log - $(date)" > "$LOG_FILE_PATH"
echo "---------------------------------" >> "$LOG_FILE_PATH"

# 4. Create a backup directory for original files
BACKUP_DIR="${TARGET_DIR}/originals_backup_$(date +%Y%m%d%H%M%S)"
mkdir -p "$BACKUP_DIR"
echo "Original files will be backed up in: $BACKUP_DIR"

# 5. Phase 1: Convert all non-WebP images to WebP in parallel
echo "Phase 1: Converting images to WebP format..."

convert_image() {
    local img_file="$1"
    local dir=$(dirname "$img_file")
    local temp_webp=$(mktemp "$dir"/XXXXXX.webp)
    echo "Converting: $img_file -> $temp_webp"
    if [ $LOSSLESS -eq 1 ]; then
        cwebp -quiet -lossless -mt "$img_file" -o "$temp_webp"
    else
        cwebp -quiet -q $QUALITY -mt "$img_file" -o "$temp_webp"
    fi
    if [ $? -eq 0 ]; then
        local rel_path="${img_file#$TARGET_DIR/}"
        mkdir -p "$BACKUP_DIR/$(dirname "$rel_path")"
        mv "$img_file" "$BACKUP_DIR/$rel_path"
        echo "Converted: $img_file -> $temp_webp" >> "$LOG_FILE_PATH"
    else
        echo "Warning: Failed to convert '$img_file'. Skipping."
        rm -f "$temp_webp"
    fi
}

export -f convert_image
export BACKUP_DIR
export LOG_FILE_PATH

find "$TARGET_DIR" -type f \( -iname "*.jpg" -o -iname "*.jpeg" -o -iname "*.png" -o -iname "*.gif" -o -iname "*.bmp" \) -print0 | xargs -0 -P "$MAX_JOBS" -I {} bash -c 'convert_image "{}"'

echo "---"
echo "Phase 1 Complete. All images converted to WebP."
echo "---"


# 6. Phase 2: Rename WebP files using Llava
echo "Phase 2: Renaming files with AI-generated SEO keywords..."

# This function is exported to be used by xargs
rename_image() {
    local webp_file="$1"
    local target_dir=$(dirname "$webp_file")

    echo "Processing: $webp_file"

    # Get base64 of the image
    local image_b64
    image_b64=$(base64 -w 0 "$webp_file")

    # Build the JSON payload for Ollama
    local payload
    payload=$(jq -n \
                  --arg model "$OLLAMA_MODEL" \
                  --arg prompt "Describe this image using exactly 10 SEO-optimized keywords separated by hyphens. Your response must ONLY contain the keywords in lowercase. Example: keyword-one-keyword-two-etc" \
                  --arg b64 "$image_b64" \
                  '{model: $model, prompt: $prompt, images: [$b64], stream: false}')

    # Call Ollama API and get the response
    local response
    local max_retries=3
    local retry_count=0
    while [ $retry_count -lt $max_retries ]; do
        response=$(curl -s -X POST "$OLLAMA_ENDPOINT" -d "$payload" --retry 3 --retry-delay 5)
        if [ $? -eq 0 ] && [ ! -z "$response" ]; then
            break
        fi
        ((retry_count++))
        echo "Retrying API call for '$webp_file' ($retry_count/$max_retries)..."
        sleep 2
    done

    if [ $retry_count -eq $max_retries ]; then
        echo "Error: Failed to get response from Ollama for '$webp_file' after $max_retries retries. Skipping."
        return
    fi


    # Extract and sanitize the new filename
    local seo_name
    seo_name=$(echo "$response" | jq -r '.response' | tr '[:upper:]' '[:lower:]' | tr -c 'a-z0-9-' '-' | sed 's/--+/-/g' | sed 's/-\$//g' | sed 's/^-+//g')
    if [ -z "$seo_name" ]; then
        echo "Warning: Could not generate name for '$webp_file'. Skipping."
        return
    fi
local base_name="$seo_name"
local new_filepath
local suffix=""
local counter=0
while true; do
    new_filepath="${target_dir}/${base_name}${suffix}.webp"
    mv -n "$webp_file" "$new_filepath"
    if [ $? -eq 0 ]; then
        # Add keywords to EXIF
        exiftool -overwrite_original -Keywords="$seo_name" "$new_filepath"
        break
    fi
    ((counter++))
    suffix="-${counter}"
done
    # Log the change
    echo "Original: $webp_file, New: $new_filepath" >> "$LOG_FILE_PATH"
    echo "Renamed: $webp_file -> $new_filepath"
}

export -f rename_image
export OLLAMA_MODEL
export OLLAMA_ENDPOINT
export LOG_FILE_PATH

# Find all .webp files and process them in parallel
find "$TARGET_DIR" -type f -iname "*.webp" -print0 | xargs -0 -P "$MAX_JOBS" -I {} bash -c 'rename_image "{}"'

echo "---"
echo "Phase 2 Complete. All files renamed."
echo "âœ… All tasks finished!"
echo "Log file is available at $LOG_FILE_PATH"
